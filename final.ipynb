{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.12.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#import torch.nn.functional as F\n",
    "from transformers import BertTokenizer #BertConfig,AdamW, \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#to_preprocessing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#from tqdm import tqdm, trange,tnrange,tqdm_notebook\n",
    "#import random\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import io\n",
    "#%matplotlib inline\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me know if this code makes sense or if y'all have any questions! \n",
    "# This is my first time doing data processing with this kind of data so there might be errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and specify the GPU as the device, later in training loop we will load data into device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.7.3 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# importing the dataset \n",
    "df_train = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/train.txt\", delimiter=';', header=None, names=['Text','Sentiment'])\n",
    "df_test = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/test.txt\", delimiter=';', header=None, names=['Text','Sentiment'])\n",
    "df_val = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/val.txt\", delimiter=';', header=None, names=['Text','Sentiment'])\n",
    "df = pd.concat([df_train, df_val, df_test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preproccessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    \"\"\"\n",
    "    We first define a function to expand the contracted phrase into normal words\n",
    "    \"\"\"\n",
    "        \n",
    "    phrase = re.sub(r\"wont\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"wouldnt\", \"would not\", phrase)\n",
    "    phrase = re.sub(r\"shouldnt\", \"should not\", phrase)\n",
    "    phrase = re.sub(r\"couldnt\", \"could not\", phrase)\n",
    "    phrase = re.sub(r\"cudnt\", \"could not\", phrase)\n",
    "    phrase = re.sub(r\"cant\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"dont\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"doesnt\", \"does not\", phrase)\n",
    "    phrase = re.sub(r\"didnt\", \"did not\", phrase)\n",
    "    phrase = re.sub(r\"wasnt\", \"was not\", phrase)\n",
    "    phrase = re.sub(r\"werent\", \"were not\", phrase)\n",
    "    phrase = re.sub(r\"havent\", \"have not\", phrase)\n",
    "    phrase = re.sub(r\"hadnt\", \"had not\", phrase)\n",
    "    phrase = re.sub(r\"neednt\", \"need not\", phrase)\n",
    "    phrase = re.sub(r\"isnt\", \"is not\", phrase)\n",
    "    phrase = re.sub(r\"arent\", \"are not\", phrase)\n",
    "    phrase = re.sub(r\"hasnt\", \"are not\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "# Get rid of user handles, tags, link, punctuation\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "#     text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = decontracted(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple cleaning function for the dataframe\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform emotion label into encoded label\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df['label_enc'] = labelencoder.fit_transform(df['Sentiment'])\n",
    "df.rename(columns={'label':'label_desc'},inplace=True)\n",
    "df.rename(columns={'label_enc':'label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_text, val_text, train_labels, val_labels = train_test_split(df['Text'], df['label'], random_state=42, test_size=0.1, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set (for Bertbase fine tuning)\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = MAX_LEN,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = MAX_LEN,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
